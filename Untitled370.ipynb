{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92def56b-eb15-4e42-b6a1-ff4ebbe7bd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "3/3 [==============================] - 4s 358ms/step - loss: 5.4768e-04 - val_loss: 0.0876\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 4.0988e-04 - val_loss: 0.0873\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 4.1209e-04 - val_loss: 0.0883\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8629e-04 - val_loss: 0.0890\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8692e-04 - val_loss: 0.0889\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.7104e-04 - val_loss: 0.0884\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.6954e-04 - val_loss: 0.0880\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.7691e-04 - val_loss: 0.0881\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.6887e-04 - val_loss: 0.0886\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.6734e-04 - val_loss: 0.0891\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.6513e-04 - val_loss: 0.0888\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.5431e-04 - val_loss: 0.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 8ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "\n",
      "‚úÖ Fish Market Supply Forecasting Completed Successfully\n",
      "üìÅ Model Saved: C:\\Users\\NXTWAVE\\Downloads\\Fish Market Supply Forecasting\\model_lstm_supply.h5\n",
      "üìÅ Results CSV: C:\\Users\\NXTWAVE\\Downloads\\Fish Market Supply Forecasting\\results.csv\n",
      "üìÅ Prediction CSV: C:\\Users\\NXTWAVE\\Downloads\\Fish Market Supply Forecasting\\predictions.csv\n",
      "üìÅ Metrics JSON: C:\\Users\\NXTWAVE\\Downloads\\Fish Market Supply Forecasting\\metrics.json\n",
      "üìÅ Config YAML: C:\\Users\\NXTWAVE\\Downloads\\Fish Market Supply Forecasting\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ============================================================\n",
    "# PATHS\n",
    "# ============================================================\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\Fish Market Supply Forecasting\"\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"Table_A-5.1.csv\")\n",
    "\n",
    "MODEL_PATH = os.path.join(BASE_DIR, \"model_lstm_supply.h5\")\n",
    "SCALER_PATH = os.path.join(BASE_DIR, \"scaler.pkl\")\n",
    "CONFIG_PATH = os.path.join(BASE_DIR, \"config.yaml\")\n",
    "METRICS_PATH = os.path.join(BASE_DIR, \"metrics.json\")\n",
    "RESULTS_CSV = os.path.join(BASE_DIR, \"results.csv\")\n",
    "PREDICTIONS_CSV = os.path.join(BASE_DIR, \"predictions.csv\")\n",
    "\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# Auto-detect numeric supply column\n",
    "target_col = df.select_dtypes(include=np.number).columns[0]\n",
    "\n",
    "data = df[[target_col]].dropna()\n",
    "\n",
    "# ============================================================\n",
    "# SCALING\n",
    "# ============================================================\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "with open(SCALER_PATH, \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# ============================================================\n",
    "# SEQUENCE CREATION\n",
    "# ============================================================\n",
    "\n",
    "def create_sequences(dataset, window=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset) - window):\n",
    "        X.append(dataset[i:i+window])\n",
    "        y.append(dataset[i+window])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "WINDOW_SIZE = 5\n",
    "X, y = create_sequences(scaled_data, WINDOW_SIZE)\n",
    "\n",
    "# Train-test split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# ============================================================\n",
    "# LSTM MODEL\n",
    "# ============================================================\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation=\"tanh\", input_shape=(WINDOW_SIZE, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\"\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save(MODEL_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# PREDICTIONS\n",
    "# ============================================================\n",
    "\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "train_pred_inv = scaler.inverse_transform(train_pred)\n",
    "y_train_inv = scaler.inverse_transform(y_train)\n",
    "\n",
    "test_pred_inv = scaler.inverse_transform(test_pred)\n",
    "y_test_inv = scaler.inverse_transform(y_test)\n",
    "\n",
    "# ============================================================\n",
    "# METRICS\n",
    "# ============================================================\n",
    "\n",
    "metrics = {\n",
    "    \"train_mae\": float(mean_absolute_error(y_train_inv, train_pred_inv)),\n",
    "    \"train_rmse\": float(np.sqrt(mean_squared_error(y_train_inv, train_pred_inv))),\n",
    "    \"test_mae\": float(mean_absolute_error(y_test_inv, test_pred_inv)),\n",
    "    \"test_rmse\": float(np.sqrt(mean_squared_error(y_test_inv, test_pred_inv))),\n",
    "    \"window_size\": WINDOW_SIZE,\n",
    "    \"model\": \"LSTM\"\n",
    "}\n",
    "\n",
    "with open(METRICS_PATH, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "# ============================================================\n",
    "# SAVE RESULTS CSV\n",
    "# ============================================================\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"actual\": y_test_inv.flatten(),\n",
    "    \"predicted\": test_pred_inv.flatten()\n",
    "})\n",
    "\n",
    "results_df.to_csv(RESULTS_CSV, index=False)\n",
    "\n",
    "# ============================================================\n",
    "# FUTURE SUPPLY PREDICTION\n",
    "# ============================================================\n",
    "\n",
    "last_sequence = scaled_data[-WINDOW_SIZE:]\n",
    "future_scaled = model.predict(last_sequence.reshape(1, WINDOW_SIZE, 1))\n",
    "future_supply = scaler.inverse_transform(future_scaled)[0][0]\n",
    "\n",
    "prediction_df = pd.DataFrame({\n",
    "    \"future_supply_prediction\": [future_supply]\n",
    "})\n",
    "\n",
    "prediction_df.to_csv(PREDICTIONS_CSV, index=False)\n",
    "\n",
    "# ============================================================\n",
    "# SAVE CONFIG YAML\n",
    "# ============================================================\n",
    "\n",
    "config = {\n",
    "    \"model\": \"LSTM\",\n",
    "    \"window_size\": WINDOW_SIZE,\n",
    "    \"epochs_trained\": len(history.history[\"loss\"]),\n",
    "    \"batch_size\": 16,\n",
    "    \"target_column\": target_col\n",
    "}\n",
    "\n",
    "with open(CONFIG_PATH, \"w\") as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "# ============================================================\n",
    "# FINAL STATUS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n‚úÖ Fish Market Supply Forecasting Completed Successfully\")\n",
    "print(f\"üìÅ Model Saved: {MODEL_PATH}\")\n",
    "print(f\"üìÅ Results CSV: {RESULTS_CSV}\")\n",
    "print(f\"üìÅ Prediction CSV: {PREDICTIONS_CSV}\")\n",
    "print(f\"üìÅ Metrics JSON: {METRICS_PATH}\")\n",
    "print(f\"üìÅ Config YAML: {CONFIG_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec766073-ef73-4dcf-810e-31911b901573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
